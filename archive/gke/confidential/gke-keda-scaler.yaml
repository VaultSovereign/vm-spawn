# KEDA ScaledObject for VaultMesh GKE
# Enables scaling from zero based on Google Cloud Pub/Sub queue depth

# Prerequisites:
# 1. KEDA installed: helm install keda kedacore/keda --namespace keda --create-namespace
# 2. Pub/Sub topic: gcloud pubsub topics create vaultmesh-jobs
# 3. Pub/Sub subscription: gcloud pubsub subscriptions create vaultmesh-jobs --topic vaultmesh-jobs
# 4. Workload Identity configured (see gke-cluster-config.yaml)

---

apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: vaultmesh-infer-scaler
  namespace: default
  labels:
    app: vaultmesh-infer
    version: v1
spec:
  # Target the VaultMesh deployment
  scaleTargetRef:
    name: vaultmesh-infer
    kind: Deployment
  
  # Scaling parameters
  minReplicaCount: 0          # Start at zero (saves cost)
  maxReplicaCount: 50         # Maximum pods (tune to your quota)
  
  # Don't scale the HPA if it exists (KEDA takes priority)
  fallback:
    failureThreshold: 3
    replicas: 0
  
  # How long to wait before scaling down
  cooldownPeriod: 300         # 5 minutes after all jobs complete
  
  # Scaling triggers based on Pub/Sub queue depth
  triggers:
    - type: gcp-pubsub
      
      metadata:
        # Pub/Sub subscription name (must exist)
        subscriptionName: vaultmesh-jobs
        
        # How to measure queue depth
        mode: MessageCount              # Count unacked messages
        
        # Target: 1 pod per 10 messages
        # E.g., 5 pending messages → 1 pod
        #       15 pending messages → 2 pods
        #       45 pending messages → 5 pods
        value: "10"
        
        # Activation threshold
        # Below this, no pods are created (stays at 0)
        activationThreshold: "5"
      
      authenticationRef:
        name: pubsub-auth

---

# KEDA authentication for Pub/Sub (uses Workload Identity)
apiVersion: keda.sh/v1alpha1
kind: TriggerAuthentication
metadata:
  name: pubsub-auth
  namespace: default
spec:
  # Use the service account linked to GCP SA via Workload Identity
  serviceAccountName: vaultmesh-agent

---

# RBAC: Allow KEDA to read deployments + get metrics
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: vaultmesh-scaler-role
  namespace: default
rules:
  - apiGroups:
      - apps
    resources:
      - deployments
      - deployments/scale
    verbs:
      - get
      - list
      - watch
      - patch
      - update
  - apiGroups:
      - ""
    resources:
      - pods
    verbs:
      - get
      - list

---

apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: vaultmesh-scaler-binding
  namespace: default
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: vaultmesh-scaler-role
subjects:
  - kind: ServiceAccount
    name: keda-operator
    namespace: keda

---

# Optional: NetworkPolicy to restrict Pub/Sub access
# Uncomment if you use network policies
# apiVersion: networking.k8s.io/v1
# kind: NetworkPolicy
# metadata:
#   name: vaultmesh-pubsub-access
#   namespace: default
# spec:
#   podSelector:
#     matchLabels:
#       app: vaultmesh-infer
#   policyTypes:
#     - Egress
#   egress:
#     # Allow DNS
#     - to:
#         - namespaceSelector: {}
#       ports:
#         - protocol: UDP
#           port: 53
#     # Allow Pub/Sub API
#     - to:
#         - namespaceSelector: {}
#       ports:
#         - protocol: TCP
#           port: 443

---

# Optional: PrometheusRule for monitoring KEDA scaling decisions
# Requires Prometheus installed in the cluster
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: vaultmesh-keda-rules
  namespace: default
spec:
  groups:
    - name: vaultmesh.scaling
      interval: 30s
      rules:
        # Alert if KEDA cannot reach Pub/Sub
        - alert: KEDAScalerUnreachable
          expr: |
            increase(keda_scaler_errors_total{scaler="gcp-pubsub",deployment="vaultmesh-infer"}[5m]) > 0
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: "KEDA cannot reach Pub/Sub for {{ $labels.deployment }}"
            description: "Scaling decisions may be delayed or stuck"
        
        # Track pending messages in queue
        - expr: |
            keda_scaler_metric_value{scaler="gcp-pubsub",deployment="vaultmesh-infer"}
          record: vaultmesh:pubsub:pending_messages
        
        # Track current pod count
        - expr: |
            keda_deployment_desired_replicas{deployment="vaultmesh-infer"}
          record: vaultmesh:current:pod_count

---

# Deployment summary and testing commands:
#
# 1. Verify KEDA is installed:
#    kubectl get pods -n keda
#    Expected: 2 keda-* pods running
#
# 2. Deploy this ScaledObject:
#    kubectl apply -f gke-keda-scaler.yaml
#
# 3. Verify ScaledObject created:
#    kubectl get scaledobject
#    kubectl describe scaledobject vaultmesh-infer-scaler
#
# 4. Publish test messages to trigger scaling:
#    for i in {1..15}; do
#      gcloud pubsub topics publish vaultmesh-jobs \
#        --message "{\"job_id\":\"test-$i\",\"model\":\"llama-70b\"}"
#    done
#
# 5. Watch scaling happen in real-time:
#    kubectl get pods -w -l app=vaultmesh-infer
#    # Expected: 0 → 1 → 2 (as messages enter queue)
#
# 6. Check KEDA metrics:
#    kubectl logs -n keda -l app=keda-operator -f
#
# 7. Monitor Pub/Sub queue:
#    gcloud pubsub subscriptions pull vaultmesh-jobs \
#      --max-messages=10 --auto-ack
#
# 8. Check scaling events:
#    kubectl get events -n default --sort-by='.lastTimestamp' | grep vaultmesh-infer

---

# Tuning Guide:
#
# Scale UP faster (more aggressive):
#   - Reduce "value" (e.g., "10" → "5"): 1 pod per 5 messages
#   - Reduce "cooldownPeriod" (e.g., "300" → "60"): Scale down quicker
#
# Scale DOWN slower (graceful):
#   - Increase "cooldownPeriod" (e.g., "300" → "900"): 15 min cooldown
#   - Ensure pods have gracefulTerminationPeriodSeconds set
#
# Cost optimization (for low-traffic):
#   - Increase "value" (e.g., "10" → "20"): 1 pod per 20 messages
#   - Increase "activationThreshold" (e.g., "5" → "20"): Don't spin up unless >20 msgs
#
# Example configurations:
#
# - Light traffic (2-3 jobs/day):
#     value: "50"
#     activationThreshold: "10"
#     cooldownPeriod: 600
#     maxReplicaCount: 5
#
# - Heavy traffic (24/7 inference):
#     value: "5"
#     activationThreshold: "0"
#     cooldownPeriod: 60
#     maxReplicaCount: 50

---

# FAQ:
#
# Q: Pods won't scale up
# A: Check Pub/Sub subscription exists, messages are being published
#    kubectl describe scaledobject vaultmesh-infer-scaler
#    gcloud pubsub subscriptions describe vaultmesh-jobs
#
# Q: Pods won't scale down to zero
# A: Ensure minReplicaCount is 0
#    Check if any pods have active connections
#    Review cooldownPeriod (5 min default)
#
# Q: Too many/too few pods created
# A: Adjust "value" (messages per pod)
#    value: "10" means 1 pod per 10 messages
#    Increase for fewer pods, decrease for more pods
#
# Q: Workload Identity not working
# A: Verify service account binding:
#    kubectl get sa vaultmesh-agent -o yaml | grep iam.gke.io
#    gcloud iam service-accounts get-iam-policy vaultmesh-workload@PROJECT.iam.gserviceaccount.com
